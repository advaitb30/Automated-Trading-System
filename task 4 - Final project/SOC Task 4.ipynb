{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88678067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af834e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        4494.649902\n",
      "1        4546.200195\n",
      "2        4732.350098\n",
      "3        4747.549805\n",
      "4        4837.549805\n",
      "            ...     \n",
      "3313    14310.799805\n",
      "3314    14504.799805\n",
      "3315    14581.450195\n",
      "3316    14617.849609\n",
      "3317    14359.450195\n",
      "Name: Close, Length: 3318, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"NSEI .csv\") #this dataset contains entries of the NIFTY 50 index of frequency 1d\n",
    "df.dropna(subset = ['Close'], inplace = True) #drops entries with empty values (checks column ['Close'])\n",
    "df = df.reset_index(drop = 'True') #this commands resets the indexes\n",
    "prices = df['Close']\n",
    "#print(df.head()) can be used to check first 5 entries\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3fbf7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rsi(prices, Window): #calculates the indicator RSI\n",
    "    delta = prices.diff(1)\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window = Window).mean()\n",
    "    avg_loss = loss.rolling(window = Window).mean()\n",
    "    rs = avg_gain/avg_loss\n",
    "    rsi = 100 - 100/(1 + rs)\n",
    "    return rsi\n",
    "\n",
    "def calculate_ema(prices, start, Window): #calculates the ema for a price\n",
    "    ema = prices.iloc[start-Window]\n",
    "    multiplier = 2/(Window + 1)\n",
    "    for i in range (start - Window, start) :\n",
    "        ema = multiplier*prices.iloc[i] + ema*(1 - multiplier)\n",
    "        #print(f\"E={ema[i]} index={i}\")\n",
    "    return ema \n",
    "\n",
    "def series_ema(prices, Window): #Applies the ema formula on a series of prices (any Series it inputs)\n",
    "    ema = pd.Series()\n",
    "    for i in range(len(df)):\n",
    "        if i < Window:\n",
    "            ema[i] = None\n",
    "        else:\n",
    "            ema[i] = calculate_ema(prices, i, Window)\n",
    "    return ema\n",
    "\n",
    "def calculate_moving_averages(prices, short_window = 12, long_window = 26): #calculates moving average (short and long ema)\n",
    "    #short_sma = prices.rolling(window = short_window).mean()\n",
    "    #long_sma = prices.rolling(window = long_window).mean()\n",
    "    short_ema = series_ema(df['Close'], 12)\n",
    "    long_ema = series_ema(df['Close'], 26)\n",
    "    df['short_ema'] = short_ema\n",
    "    df['long_ema'] = long_ema\n",
    "    df.dropna(subset = ['long_ema'], inplace = True)\n",
    "    return short_ema, long_ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa30a2de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date          Open          High           Low         Close  \\\n",
      "0     2007-10-24   5477.600098   5577.899902   5419.399902   5496.149902   \n",
      "1     2007-10-25   5499.049805   5605.950195   5469.299805   5568.950195   \n",
      "2     2007-10-26   5564.250000   5716.899902   5513.350098   5702.299805   \n",
      "3     2007-10-29   5708.899902   5922.500000   5708.899902   5905.899902   \n",
      "4     2007-10-30   5917.549805   5976.000000   5833.899902   5868.750000   \n",
      "...          ...           ...           ...           ...           ...   \n",
      "3261  2021-03-02  14865.299805  14959.099609  14760.799805  14919.099609   \n",
      "3262  2021-03-03  15064.400391  15273.150391  14995.799805  15245.599609   \n",
      "3263  2021-03-04  15026.750000  15202.349609  14980.200195  15080.750000   \n",
      "3264  2021-03-05  14977.950195  15092.349609  14862.099609  14938.099609   \n",
      "3265  2021-03-08  15002.450195  15111.150391  14919.900391  14956.200195   \n",
      "\n",
      "         Adj Close    Volume     short_ema      long_ema        MACD  \\\n",
      "0      5496.149902       0.0   5359.604578   5174.270762  185.333816   \n",
      "1      5568.950195       0.0   5413.230975   5205.083352  208.147623   \n",
      "2      5702.299805       0.0   5452.571409   5257.204247  195.367162   \n",
      "3      5905.899902       0.0    5502.22576   5292.229315  209.996445   \n",
      "4      5868.750000       0.0    5551.31671   5349.854555  201.462156   \n",
      "...            ...       ...           ...           ...         ...   \n",
      "3261  14919.099609  621700.0  14925.308427  14801.695109  123.613318   \n",
      "3262  15245.599609  544200.0  14944.748003  14792.409904  152.338099   \n",
      "3263  15080.750000  534900.0  14990.864481    14789.2857  201.578781   \n",
      "3264  14938.099609  640700.0  14990.609372  14790.602117  200.007255   \n",
      "3265  14956.200195       0.0  14970.413975  14776.792668  193.621307   \n",
      "\n",
      "             SL  \n",
      "0     51.990009  \n",
      "1     47.181225  \n",
      "2     35.208552  \n",
      "3     23.720261  \n",
      "4     13.727862  \n",
      "...         ...  \n",
      "3261 -75.187965  \n",
      "3262 -65.365874  \n",
      "3263 -79.512583  \n",
      "3264 -90.643115  \n",
      "3265 -91.674576  \n",
      "\n",
      "[3266 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "short_ema, long_ema = calculate_moving_averages(prices)\n",
    "MACD = df['short_ema'] - df['long_ema'] #formula of MACD\n",
    "df['MACD'] = MACD #inserts a column for MACD\n",
    "signal_line = series_ema(df['MACD'], 9)\n",
    "df['SL'] = signal_line #inserts acolumn for signal line\n",
    "df.dropna(subset = ['SL'], inplace = True) #cleans the data, getting rid of entries with NULL values in signal line column\n",
    "df = df.reset_index(drop = 'True')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f328954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pc(prices): #calculates percentage chane from previous day's closing to current day's closing\n",
    "    cpc = pd.Series()\n",
    "    for i in range(len(df)):\n",
    "        if i == 0:\n",
    "            cpc[i] = None\n",
    "        else:\n",
    "            cpc[i] = ((prices.iloc[i] - prices.iloc[i-1])/prices.iloc[i-1])*100\n",
    "    return cpc\n",
    "\n",
    "def calculate_obv(): #calculates the \"on-balance volume indicator\"\n",
    "    obv = pd.Series()\n",
    "    for i in range(len(df)):\n",
    "        if i == 0:\n",
    "            obv[i] = df.loc[i, 'Volume']\n",
    "        else:\n",
    "            if(df.loc[i, 'Close'] > df.loc[i-1, 'Close']):\n",
    "                obv[i] = obv.iloc[i-1] + df.loc[i, 'Volume']\n",
    "            elif(df.loc[i, 'Close'] < df.loc[i-1, 'Close']):\n",
    "                obv[i] = obv.iloc[i-1] - df.loc[i, 'Volume']\n",
    "            else:\n",
    "                obv[i] = obv.iloc[i-1]\n",
    "    return obv\n",
    "\n",
    "def calculate_target(): #target value(y) contains binary values for either buying or selling()\n",
    "    target = pd.Series()\n",
    "    for i in range(len(df) - 1):\n",
    "            if(df.loc[i+1, 'Close'] > df.loc[i, 'Close']):\n",
    "                target[i] = 1\n",
    "            else:\n",
    "                target[i] = 0\n",
    "    return target\n",
    "\n",
    "def williamsR(period): #calculates the indicator williamsR\n",
    "    k = pd.Series()\n",
    "    for i in range(len(df)):\n",
    "        if i < 26:\n",
    "            k[i] = 0\n",
    "        else:\n",
    "            current = df.loc[i,'Close']\n",
    "            high_period = df.loc[i-period:i, 'High'].max()\n",
    "            low_period = df.loc[i-period:i, 'Low'].min()\n",
    "            k[i] = (current - high_period)/(high_period - low_period)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb62059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSI = calculate_rsi(df['Close'], 14)\n",
    "df['RSI'] = RSI #inserts a column for MACD\n",
    "EMA50 = series_ema(df['Close'], 50)\n",
    "df['ema50'] = EMA50 #inserts a column for EMA50w\n",
    "CO = df['Close'] - df['Open']\n",
    "df['close-open'] = CO #inserts a column for close-open difference for current day's price\n",
    "HL = df['High'] - df['Low']\n",
    "df['High- Low'] = HL #inserts a column for High-Low difference in current day's price\n",
    "k = williamsR(14)\n",
    "df['WR'] = k #inserts a column for WilliamsR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efa39f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date          Open          High           Low         Close  \\\n",
      "0     2007-10-24   5477.600098   5577.899902   5419.399902   5496.149902   \n",
      "1     2007-10-25   5499.049805   5605.950195   5469.299805   5568.950195   \n",
      "2     2007-10-26   5564.250000   5716.899902   5513.350098   5702.299805   \n",
      "3     2007-10-29   5708.899902   5922.500000   5708.899902   5905.899902   \n",
      "4     2007-10-30   5917.549805   5976.000000   5833.899902   5868.750000   \n",
      "...          ...           ...           ...           ...           ...   \n",
      "3261  2021-03-02  14865.299805  14959.099609  14760.799805  14919.099609   \n",
      "3262  2021-03-03  15064.400391  15273.150391  14995.799805  15245.599609   \n",
      "3263  2021-03-04  15026.750000  15202.349609  14980.200195  15080.750000   \n",
      "3264  2021-03-05  14977.950195  15092.349609  14862.099609  14938.099609   \n",
      "3265  2021-03-08  15002.450195  15111.150391  14919.900391  14956.200195   \n",
      "\n",
      "         Adj Close    Volume     short_ema      long_ema        MACD  \\\n",
      "0      5496.149902       0.0   5359.604578   5174.270762  185.333816   \n",
      "1      5568.950195       0.0   5413.230975   5205.083352  208.147623   \n",
      "2      5702.299805       0.0   5452.571409   5257.204247  195.367162   \n",
      "3      5905.899902       0.0    5502.22576   5292.229315  209.996445   \n",
      "4      5868.750000       0.0    5551.31671   5349.854555  201.462156   \n",
      "...            ...       ...           ...           ...         ...   \n",
      "3261  14919.099609  621700.0  14925.308427  14801.695109  123.613318   \n",
      "3262  15245.599609  544200.0  14944.748003  14792.409904  152.338099   \n",
      "3263  15080.750000  534900.0  14990.864481    14789.2857  201.578781   \n",
      "3264  14938.099609  640700.0  14990.609372  14790.602117  200.007255   \n",
      "3265  14956.200195       0.0  14970.413975  14776.792668  193.621307   \n",
      "\n",
      "             SL        RSI         ema50  close-open   High- Low        WR  \n",
      "0     51.990009        NaN          None   18.549804  158.500000  0.000000  \n",
      "1     47.181225        NaN          None   69.900390  136.650390  0.000000  \n",
      "2     35.208552        NaN          None  138.049805  203.549804  0.000000  \n",
      "3     23.720261        NaN          None  197.000000  213.600098  0.000000  \n",
      "4     13.727862        NaN          None  -48.799805  142.100098  0.000000  \n",
      "...         ...        ...           ...         ...         ...       ...  \n",
      "3261 -75.187965  45.829983  14551.278316   53.799804  198.299804 -0.531795  \n",
      "3262 -65.365874  51.442132  14568.388317  181.199218  277.350586 -0.193102  \n",
      "3263 -79.512583  48.449214  14536.476157   54.000000  222.149414 -0.364108  \n",
      "3264 -90.643115  42.901823  14576.477908  -39.850586  230.250000 -0.512085  \n",
      "3265 -91.674576  43.309044  14608.897456  -46.250000  191.250000 -0.493309  \n",
      "\n",
      "[3266 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c458e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPC = calculate_pc(df['Close'])\n",
    "OBV = calculate_obv()\n",
    "y = calculate_target()\n",
    "df['cpc'] = CPC #inserts a column for percentage change\n",
    "df['obv'] = OBV #inserts a column for obv\n",
    "df['Y'] = y #inserts a column for target value(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83c5a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation of features\n",
    "df['normMACD'] = (df['MACD'] - df['MACD'].mean())/df['MACD'].std()\n",
    "df['normSL'] = (df['SL'] - df['SL'].mean())/df['SL'].std()\n",
    "df['RSI'] = df['RSI']/10\n",
    "df['close-open'] = (df['close-open'] - df['close-open'].min())/(df['close-open'].max() - df['close-open'].min())\n",
    "df['High- Low'] = (df['High- Low'] - df['High- Low'].min())/(df['High- Low'].max() - df['High- Low'].min())\n",
    "df['obv'] = (df['obv'] - df['obv'].min())/(df['obv'].max() - df['obv'].min())\n",
    "df['ema50'] = (df['ema50'] - df['ema50'].mean())/(df['ema50'].std())\n",
    "df['WR'] = (df['WR'] - df['WR'].mean())/(df['WR'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f067a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date          Open          High           Low         Close  \\\n",
      "0     2008-01-07   6271.000000   6289.799805   6193.350098   6279.100098   \n",
      "1     2008-01-08   6282.450195   6357.100098   6221.600098   6287.850098   \n",
      "2     2008-01-09   6287.549805   6338.299805   6231.250000   6272.000000   \n",
      "3     2008-01-10   6278.100098   6347.000000   6142.899902   6156.950195   \n",
      "4     2008-01-11   6166.649902   6224.200195   6112.549805   6200.100098   \n",
      "...          ...           ...           ...           ...           ...   \n",
      "3211  2021-03-02  14865.299805  14959.099609  14760.799805  14919.099609   \n",
      "3212  2021-03-03  15064.400391  15273.150391  14995.799805  15245.599609   \n",
      "3213  2021-03-04  15026.750000  15202.349609  14980.200195  15080.750000   \n",
      "3214  2021-03-05  14977.950195  15092.349609  14862.099609  14938.099609   \n",
      "3215  2021-03-08  15002.450195  15111.150391  14919.900391  14956.200195   \n",
      "\n",
      "         Adj Close    Volume     short_ema      long_ema        MACD  ...  \\\n",
      "0      6279.100098       0.0   6066.070674   5976.899716   89.170958  ...   \n",
      "1      6287.850098       0.0   6100.036607   6001.590159   98.446447  ...   \n",
      "2      6272.000000       0.0   6130.998764   6040.120692   90.878072  ...   \n",
      "3      6156.950195       0.0    6182.13835   6071.121317  111.017032  ...   \n",
      "4      6200.100098       0.0   6189.800939   6076.579934  113.221005  ...   \n",
      "...            ...       ...           ...           ...         ...  ...   \n",
      "3211  14919.099609  621700.0  14925.308427  14801.695109  123.613318  ...   \n",
      "3212  15245.599609  544200.0  14944.748003  14792.409904  152.338099  ...   \n",
      "3213  15080.750000  534900.0  14990.864481    14789.2857  201.578781  ...   \n",
      "3214  14938.099609  640700.0  14990.609372  14790.602117  200.007255  ...   \n",
      "3215  14956.200195       0.0  14970.413975  14776.792668  193.621307  ...   \n",
      "\n",
      "           RSI     ema50 close-open  High- Low        WR       cpc       obv  \\\n",
      "0     6.365190 -0.625328   0.427841   0.060121  1.186166  0.076507  0.034906   \n",
      "1     9.362137 -0.615641   0.426001   0.084463  0.971753  0.139351  0.034906   \n",
      "2     9.673549 -0.603096   0.411723   0.066729  0.898484 -0.252075  0.034906   \n",
      "3     8.015309 -0.587675   0.339751   0.127225  0.366648  -1.83434  0.034906   \n",
      "4     8.094051 -0.586922   0.445119   0.069597  0.488087  0.700832  0.034906   \n",
      "...        ...       ...        ...        ...       ...       ...       ...   \n",
      "3211  4.582998  2.663542   0.458988   0.123609 -0.380760  1.067299  0.959398   \n",
      "3212  5.144213   2.67003   0.545816   0.172885  0.684517   2.18847  0.969339   \n",
      "3213  4.844921  2.657928   0.459124   0.138476  0.146659 -1.081293  0.959568   \n",
      "3214  4.290182  2.673098   0.395161   0.143525 -0.318768  -0.94591  0.947863   \n",
      "3215  4.330904  2.685393   0.390799   0.119215 -0.259711  0.121171  0.947863   \n",
      "\n",
      "        Y  normMACD    normSL  \n",
      "0     1.0  0.550346 -2.470501  \n",
      "1     0.0  0.622279 -2.476654  \n",
      "2     0.0  0.563585 -2.508562  \n",
      "3     1.0  0.719766 -2.480153  \n",
      "4     1.0  0.736858 -2.435078  \n",
      "...   ...       ...       ...  \n",
      "3211  1.0  0.817453 -0.749548  \n",
      "3212  0.0  1.040218 -0.669481  \n",
      "3213  0.0  1.422088 -0.784802  \n",
      "3214  1.0  1.409901 -0.875535  \n",
      "3215  NaN  1.360377 -0.883943  \n",
      "\n",
      "[3216 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset = ['ema50'], inplace = True) #drops all the entries with NULL values in the column 'ema50'\n",
    "df = df.reset_index(drop = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98409263",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['RSI', 'ema50', 'close-open', 'High- Low', 'WR', 'cpc', 'normMACD', 'normSL']\n",
    "X = df[features]\n",
    "Y = df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "359e80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting features on a 80-20 basis\n",
    "X_train = X.loc[:2572]\n",
    "Y_train = Y.loc[:2572]\n",
    "X_test = X.loc[2573:]\n",
    "Y_test = Y.loc[2573:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef34747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2869\n",
      "Epoch 2/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2520\n",
      "Epoch 3/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2482\n",
      "Epoch 4/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2462\n",
      "Epoch 5/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2442\n",
      "Epoch 6/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2434\n",
      "Epoch 7/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2430\n",
      "Epoch 8/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2427\n",
      "Epoch 9/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2425\n",
      "Epoch 10/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2424\n",
      "Epoch 11/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.0000e+00 - loss: 0.2422\n",
      "Epoch 12/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2422\n",
      "Epoch 13/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2420\n",
      "Epoch 14/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2420\n",
      "Epoch 15/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2419\n",
      "Epoch 16/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2419\n",
      "Epoch 17/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.0000e+00 - loss: 0.2418\n",
      "Epoch 18/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2418\n",
      "Epoch 19/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2418\n",
      "Epoch 20/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2418\n",
      "Epoch 21/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2418\n",
      "Epoch 22/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 23/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 24/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 25/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 26/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 27/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 28/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 29/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 30/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 31/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 32/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 33/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 34/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 35/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 36/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 37/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 38/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 39/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 40/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 41/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 42/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 43/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 44/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 45/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 46/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 47/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 48/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 49/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 50/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 51/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 52/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 53/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 54/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 55/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 56/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 57/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 58/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 59/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 60/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 61/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 62/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 63/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 64/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 65/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 66/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 67/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 68/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 69/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 70/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 71/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 72/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 73/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 74/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 75/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 76/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 77/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 78/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 79/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 80/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 81/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 82/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 83/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 84/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 85/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 86/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 87/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 88/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 89/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 90/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 91/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 92/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 93/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 94/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 95/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 96/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 97/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 98/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 99/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 100/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 101/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 102/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 103/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 104/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 105/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 106/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 107/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 108/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 109/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 110/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 111/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 112/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 113/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 114/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 115/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 116/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 117/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 118/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 119/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 120/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 121/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 122/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 123/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 124/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 125/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 126/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 127/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 128/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 129/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 130/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2416\n",
      "Epoch 131/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 132/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 133/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 134/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 135/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2417\n",
      "Epoch 136/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 137/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 138/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 139/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 140/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 141/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 142/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 143/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 144/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 145/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 146/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415  \n",
      "Epoch 147/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 148/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 149/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n",
      "Epoch 150/150\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.2415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c936518ed0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the neural network using tensorflow(keras)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "tf.random.set_seed(1234)\n",
    "model = Sequential(\n",
    "[\n",
    "    tf.keras.Input(shape = (8, )),\n",
    "    Dense(units = 120, activation = 'linear', name = 'Layer1'),\n",
    "    Dense(units = 40, activation = 'linear', name = 'Layer2'),\n",
    "    Dense(units = 4, activation = 'linear', name = 'Layer3'),\n",
    "    Dense(units = 1, activation = 'sigmoid', name = 'Output')\n",
    "])\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.003),\n",
    "    metrics = [tf.keras.metrics.Accuracy()]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, Y_train,            \n",
    "    epochs = 150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78a6e513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "2573    1.0\n",
      "2574    0.0\n",
      "2575    1.0\n",
      "2576    1.0\n",
      "2577    1.0\n",
      "       ... \n",
      "3211    1.0\n",
      "3212    0.0\n",
      "3213    0.0\n",
      "3214    1.0\n",
      "3215    NaN\n",
      "Name: Y, Length: 643, dtype: float64\n",
      "0.578538102643857\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(X_test)\n",
    "Y_test.reset_index(drop = True)\n",
    "print(Y_test)\n",
    "for i in range(len(predict)):\n",
    "    if(predict[i] > 0.5):\n",
    "        predict[i] = 1\n",
    "    else:\n",
    "        predict[i] = 0\n",
    "count = 0\n",
    "for j in range(len(Y_test)):\n",
    "    if(Y_test[j+2573] == predict[j]):\n",
    "        count += 1\n",
    "print(count/len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5501e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
